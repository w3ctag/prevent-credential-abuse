<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8">
    <title>Preventing Abuse of Digital Credentials</title>
    <script
      defer
      class="remove"
      src="https://www.w3.org/Tools/respec/respec-w3c">
    </script>
    <script class="remove">
var respecConfig = {
  specStatus: "draft-finding",
  editors: [
    {
      name: "Daniel Appelquist",
      company: "Samsung Electronics",
    },
    {
      name: "Martin Thomson",
      company: "Mozilla",
    },
  ],
  group: "tag",
  wgPublicList: "www-tag",
  github: "w3ctag/web-no-papers",
  format: "markdown",
  localBiblio: {
    "AADHAAR-MANDATORY": {
      title: "Ten Things For Which Aadhaar Was Made Mandatory Even After an October 2015 Supreme Court Order to the Contrary",
      href: "https://caravanmagazine.in/vantage/aadhaar-mandatory-supreme-court-order-2015",
      date: "2017-01-18",
      publisher: "The Caravan",
    },
    "AGE-WS": {
      title: "IAB/W3C Workshop on Age-Based Restrictions on Content Access",
      href: "https://datatracker.ietf.org/group/agews/about/",
      date: "2025-07-15",
    },
    "COUNCIL-REPORT": {
      title: "W3C Council Report on the Formal Objection Against Federated Identity Working Group Charter â€” Adding Digital Credentials API",
      href: "https://www.w3.org/2025/02/council-report-fedid-dig-cred.html",
      date: "2025-02-20",
    },
    "OBJECTION": {
      title: "[/wg/fedid] Formal Objection (charter review)",
      href: "https://lists.w3.org/Archives/Public/public-review-comments/2024Sep/0017.html",
      date: "2024-09-12",
      publisher: "W3C",
    },
    "SUPPRESS": {
      title: "The \"Segregate-and-Suppress\" Approach to Regulating Child Safety Online",
      href: "https://papers.ssrn.com/sol3/papers.cfm?abstract_id=5208739",
      date: "2025-04-08",
      authors: ["Eric Goldman"],
    },
  },
};
</script>
<style>
#toc a.tocxref[href="#references"] + ol.toc,
#informative-references > .header-wrapper
{
  display: none;
}
</style>
</head>
<body class="informative">
<section id="abstract">
The use of digital identity for web users
presents many opportunities for abuse.
This risk is heightened
when legal names or identities are involved.
This document explores some of these risks,
with a focus on the presentation of government-issued digital credentials.
Misuse of these systems risks
doing irreparable harm to individual autonomy online.
</section>

<section id="sotd">
This is a draft TAG finding and does not yet represent TAG consensus.
</section>

## Background

APIs that facilitate access to verifiable claims about identity,
such as the proposed [Digital Credentials API](https://wicg.github.io/digital-credentials/),
are starting to be developed and deployed.
A large number of jurisdictions are starting
to create digital identity systems for their citizens.

The [Federated Identity Working Group](https://www.w3.org/2025/02/wg-fedid.html)
includes an API for accessing these systems
as a chartered deliverable.
This API follows a three-party model
where the primary actors are the [=issuer=], [=holder=], and [=verifier=];
as defined in [[VC-DATA-MODEL-2.0]].

Digital identity APIs provide a convenient way
for websites to access proof of legal identity.
This convenience leads to a range of implications for privacy,
as noted in a recent objection
to the formation of the Federated Identity Working Group [[OBJECTION]].

The TAG believes that the addition of government-issued digital credentials
to the web has great potential to cause the harms listed in the objection:

* Increased sharing of personal data
  and corresponding reduction of privacy
  due to reduced friction for sharing such data.
* Increased centralization of trust on the Web.
* Increased restriction of the ability
  to publish, view, and participate on the Web,
  and corresponding fragmentation of the Web as a whole.
* Reduction of user agency and perpetuation of existing societal power imbalances.
* Expansion of use cases such as age verification
  where credentials may be requested or required inappropriately or coercively,
  raising concerns about government or platform overreach.

The report produced by the W3C Council [[COUNCIL-REPORT]]
also acknowledged these problems
and [recommended](https://www.w3.org/2025/02/council-report-fedid-dig-cred.html#x1-recommendations)
that these concerns be addressed in the work of the Working Group.


## Finding Summary

The TAG believes that the addition of government-issued digital credentials to the web
has great potential for harm.

The benefits of digital credentials
must be aligned with the [web user's needs](https://www.w3.org/TR/design-principles/#priority-of-constituencies).
Following our established [principles for privacy](https://w3ctag.github.io/privacy-principles/),
this includes providing people the tools to understand and control
how their personal information is collected and used.
A browser &mdash;
or user agent &mdash;
plays an essential role
in mediating these types of requests
and ensuring that people have agency.

The web should not become a platform that demands your government-issued identity documents
in the course of its normal operation.
Use of such credentials should be exceptional,
only when required,
and always on a person's own terms.

The TAG therefore encourages contributors
to pay special attention to the societal impact of digital credentials.


## Uses for Identity Information {#reasons}

There are multiple reasons that a site might seek to ask for proof of legal identity.
Often, there are multiple reasons that a site seeks to identify a visitor.

Motivations that tend to produce user-beneficial outcomes include:

* Obtaining some means of holding a person accountable
  for a range of abusive behavior.
* Avoiding impersonation,
  especially for social media accounts of prominent individuals or organizations.
* Legal mandates,
  such as know-your-customer regulations common to financial services.

These uses are not necessarily directly felt
by people who are required to present credentials,
but they can provide a societal benefit
that outweighs the costs to individuals.
Each of these still carries the potential for abuse.

There are also motivations
for which requesting identification is not justified
and those that are outright harmful to end user interests:

* Distinguishing between visits from real people and visits from bots,
  which might need to be handled specially.
* Personalization,
  such as being able to appear more friendly by greeting a person by their name.
* Tracking,
  which takes identity presented to multiple contexts
  and links that activity to a single person.

That is, while at least _some_ of these goals are beneficial,
the use of identity documents is not appropriate.
Any benefits are not justified by the cost
that people pay in terms of losing their ability to control
[the identity they present](https://w3ctag.github.io/privacy-principles/#principle-identity-per-context)
[[PRIVACY-PRINCIPLES]].
Other goals are inherently objectionable.


## Tracking with Legal Identity {#tracking}

Once someone has provided legal identity,
sites are technically able to use identifiers in any way they choose.
Technical privacy protections that might be implemented in a browser cannot help.
Legal protections might apply to misuse of identifying information,
but that depends on effective detection and enforcement.

Tracking practices are moving away from largely hidden mechanisms &mdash;
like cookies &mdash;
to systems that require the use of stable identifiers.
Once identifying information is provided,
sites might then assume that they have consent to use identifiers
for a range of purposes.
Of course, without a viable alternative,
any consent to use identifiers is a fiction.

Perhaps the most serious consequence of obtaining an identifier
is that sites are then able to trade information
across any contexts where a person has provided that same identifier,
online or offline.
The resulting profiles are then used for many purposes
including advertising, credit ratings, and market analysis.

The TAG regards [unsanctioned tracking as unacceptable](https://www.w3.org/2001/tag/doc/unsanctioned-tracking/)
and has advocated for technical measures that curtail these practices.
The TAG has also unequivocally
[condemned cross-site cookies and called for browsers to disable them](https://www.w3.org/2001/tag/doc/web-without-3p-cookies/).

Technical measures to prevent tracking are consistent
with the TAG's [documented principles for privacy](https://w3ctag.github.io/privacy-principles/).
These principles articulate why privacy is essential to maintaining personal autonomy.
The same high-level principles are shared
by the many jurisdictions that have implemented data protection legislation.
The goal of data protection is to protect a person's rights over how data about them is used.

Absent the ability to request legal identity,
sites might ask for other identifiers,
like an email address, credit card, mailing address, or phone number.
Those identifiers could offer more privacy options, to varying degrees.
For instance, email services can provide temporary or site-specific aliases
to enable the creation of context-specific addresses on demand.
Similar aliasing is achievable
for other types of identifiers that are in common use,
though it can be both significantly harder and more expensive.
No such flexibility is possible when it comes to legal identity.


## Overuse of Identity

A streamlined process for providing verifiable identity
reduces the cost of requesting and providing that information.
In turn, this will make sites that would otherwise not ask for information
choose to take advantage of reduced friction to make a request.

Though increasing friction might not be worthwhile,
other mechanisms might be used to disincentivise requests for legal identity.
A method that might alter the costs for site operators
is described in [[[#auth]]].

Normalizing the practice of providing identity credentials to websites
risks serious harm.
Providing any form of external identity information needs to be an exceptional process.

For example, it is entirely inappropriate to use government-issued credentials
as a login credential,
even if credentials are used during account creation.


### Case Study: Aadhaar {#aadhaar}

That digital credentials might be used to track people is not a fancy of science fiction,
it is the lived experience of a very large number of people.

In India,
the [Aadhaar](https://uidai.gov.in/) national identity scheme
was introduced as a way to enable access to government services,
like health, welfare, and food assistance.
Though the legislation
originally included the option for Aadhaar to be used by non-government actors,
that provision
(Section 57)
was ruled [unconstitutional](https://www.thehindu.com/news/resources/article25048939.ece/binary/AadhaarVerdict.pdf)
by the Supreme Court in 2018.

In 2025,
the Indian government has enabled wide use of Aadhar for any entity,
expanding the set of recognized reasons
to include "[promoting ease of living for residents](https://pib.gov.in/PressReleaseIframePage.aspx?PRID=2098223)".
As a result,
the roughly 1 billion Indian participants in the Aadhaar program
are potentially subject to surveillance through the use of their unique 12 digit identifier,
which links fingerprints and iris scans to name and other personal details.

Despite Aadhar use being optional in law,
even prior to this change,
refusals to do business were widespread in employment
and other non-government interactions.
A number of government services soon
made Aadhaar use mandatory [[AADHAAR-MANDATORY]].
This further highlights the need for accountability,
but also demonstrates that there are strong incentives
that motivate the use of legal identity where it is available.
Privacy therefore depends on having an equivalently strong countervailing force.


### Age Verification {#age}

A number of governments have chosen to mandate the use of age verification
for access to certain online services.
The TAG is not confident that age verification is even appropriate ([[SUPPRESS]]),
but we are waiting for the outcome of the upcoming [[AGE-WS]] workshop
before taking a firm position.

Different jurisdictions vary in how they require age verification,
but a common theme is to place the responsibility on the service provider
(the website, in the web's context).
The presentation of government-issued credentials
is often recognized as an acceptable age verification method;
in other cases, government credentials are one of a set of acceptable methods.

Even if privacy concerns around surveillance are mitigated,
the use of credentials in this setting creates another way in which
people might become accustomed to providing their identity documents.
Use of credentials for age verification therefore leads to credential overuse.


## Exclusion {#exclusion}

Online services that have [real-name policies](https://en.wikipedia.org/wiki/Real-name_system)
are justifiably controversial.
The use of legal identity provides very different social dynamics
when compared with [pseudonymous](https://www.eff.org/deeplinks/2011/07/case-pseudonyms)
or anonymous systems.

Insistence on use of legal identity inevitably excludes certain people,
which can be for a range of reasons:

* Sites that only recognize credentials from local authorities
  could unjustly exclude people from out of town,
  either temporarily or permanently.
* People might wish to remain anonymous
  for any reason,
  including fear of harm to their reputation or person.
* People might temporarily lose access to credentials
  because of a lost personal device
  or temporary disability.
* People might be completely unable to obtain or use credentials.
* Systems that include the ability to revoke credentials
  can be abused by attackers
  to forcibly exclude people.

In some cases,
such as Aadhaar ([[[#aadhaar]]]),
the law recognizes the risk that people might not be able to produce evidence
that they hold a credential
and forbids discrimination against those who do not authenticate.
However, what matters is whether refusal is respected in practice.

Even if laws only permit the use of digital credentials as a convenience,
there is a risk that no alternative means of access to services are provided.
This leads to exclusion.

It should not be possible to refuse service to a person
based on their refusal or inability to provide a digital credential.
This is aligned with such principles
as [not revealing when assistive technologies are in use](https://www.w3.org/TR/design-principles/#do-not-expose-use-of-assistive-tech)
or [non-retaliation](https://www.w3.org/TR/privacy-principles/#non-retaliation).


### Centralization of Trust

Any website that requests legal identifiers
needs to decide which legal identities it accepts.
The easiest way to do this is to trust the issuers of credentials
that are most-used among visitors
and distrust the rest.
Another way might be to choose government-issued credentials
from jurisdictions in which the site has a legal presence.
This risks centralization of trust in the most-used credentials
and makes it hard for any new authority to become trusted.

Centralizing trust in a limited set of authorities
can lead to a fragmented web,
where access depends on which authorities
a site or user is willing, or able, to work with.

Choosing a limited set of issuers also risks marginalizing people
who are unable to obtain credentials that will be accepted.
There might be many reasons why someone cannot get a credential.
The choice of jurisdiction is not often something that a user can choose,
but instead one dictated by factors outside of their control.
This could undermine the global and open nature of the web.

For example, a visitor, migrant, or refugee
may not be able to &mdash; or may not feel safe to &mdash; use credentials
from their country of origin.
Especially where major platforms only recognize a narrow set of issuers,
or only recognize issuers tied to a specific jurisdiction.


### Centralization of Control

The implementation of identity verification is complex.
Sites might choose to delegate to external services to manage the process.

It is possible that a limited number of service providers
will be capable of implementing the technical and legal process
of gathering and validating credentials.
This is presently the case for payments infrastructure,
which has high degrees of consolidation.

Centralized control provides opportunities to use &mdash;
or, depending on perspective, abuse &mdash;
the power it confers to advance political goals.
For instance, centralized control over access to payments infrastructure
has been used to [refuse business](https://stripe.com/au/legal/restricted-businesses#prohibited-businesses)
from [sex work](https://www.aclu.org/news/lgbtq-rights/how-mastercard-is-endangering-sex-workers),
[legal drugs](https://thejointllc.com/cash-only-cannabis/),
and [video games](https://pressspacetojump.com/feature/on-itch-io-payment-processors-and-the-developers-and-creatives-affected/).

Open standards and implementations can help
reduce this risk of capture.
Designing systems and standards to minimize any structural bias
that might lead to market consolidation is better.


## Use Cases and Technical Options

Sites seek to obtain and use identity for multiple reasons; see [[[#reasons]]].
While the universality of a generic solution is appealing,
each use case might require a different type of solution.
Different solutions can have dramatically different privacy characteristics.

The properties of different approaches need to be understood and matched to needs.
A possible [data minimization](https://w3ctag.github.io/privacy-principles/#data-minimization) approach might choose to use selective disclosure,
so that people can choose what is disclosed to sites.
Such a system can accept the [linkability risks](https://datatracker.ietf.org/doc/html/draft-ietf-oauth-selective-disclosure-jwt-17#name-unlinkability)
on the basis of the need for identifying information.
Such a system might instead avoid identifying information,
but rely on linkability as an essential feature,
because it might be used to trace bad actors when necessary.
These are very different reasons to use the same technique,
with dramatically different privacy and control characteristics.

A system that seeks to authorize based on certain traits &mdash;
such as a system to authorize access to online gambling,
something that might be restricted by age or past history of susceptibility &mdash;
might be best suited to a zero-knowledge system
that provides strong unlinkability.

This highlights that there is no single approach
that will work in all cases.
For a web API, like digital credentials,
this is challenging,
because such APIs need to serve a range of purposes.
However, this highlights that it is unlikely to be clear to the people
who need to authorize use of their credentials
whether the system they are participating in
has adequate safeguards for the situation.

Developing a better understanding of what is appropriate
for a given situation
will take time.
Developing the necessary understanding of different uses of new technology &mdash;
and then evolving norms to handle those situations &mdash;
is not something that can be rushed.
[Deployment](https://developer.apple.com/videos/play/wwdc2025/232/) [is](https://developer.chrome.com/blog/digital-credentials-api-origin-trial).


### Authorizing Use {#auth-use}

Many uses of digital credentials will rely on asking people to make a decision
about whether to authorize the use of the credential.

User agents need to help their users understand what information is disclosed
to enable an informed choice.
It is challenging to design a system
that can accurately and comprehensibly convey the details
of what people are being asked to approve
given the potential diversity of uses.
Communicating the implications can be particularly difficult
when credentials are linkable
or reveal metadata, such as the issuer identity.


### Authorizing Sites {#auth}

The architecture specified in the European Unionâ€™s [digital identity eIDAS regulation](https://www.european-digital-identity-regulation.com/Preamble_11_to_20_%28Regulation_EU_2024_1183%29.html)
envisions not only the issuance of digital credentials to individuals,
but also the explicit authorization of businesses and service providers that will request those credentials.

These business or government entities (known as "relying parties")
must be registered and approved by identity issuers,
before they are granted permission to access the system.
Relying parties can then request only the information they received approval for.
This design is intended to ensure that businesses and agencies cannot request arbitrary personal data,
and that their ability to do so is constrained, transparent, and subject to oversight.

This depends on having a system for transparency:

> relying parties should provide information regarding the data that they will request,
> if any, in order to provide their services and the reason for the request.

Verifiable transparency mechanisms contribute to accountability
by making it possible for users to understand who is asking for what,
and under what legal authority.
This safeguard mitigates against some of the risks associated with digital credentials.
However, it does not eliminate the need for scrutiny,
particularly with regard to proportionality of use,
user control, and the risk of such mechanisms becoming normalized across the web.
Nevertheless, we recommend that the specification authors
look to such mechanisms as a guide for mitigating
potential harms in this area.


### Multiple National Credentials

Individuals with more than one nationality, when traveling across international borders,
have the choice of which credential (passport) to assert.
For example, a person is generally required to present a passport
for the country they entering if they are a citizen of that country,
even if they hold other passports.
When entering a country in which they do not hold citizenship,
individuals with multiple nationalities have the choice of asserting
whichever nationality is more convenient.

The systems that support digital passport credentials &mdash;
and therefore enable these assertions to move to the digital domain &mdash;
should not behave any differently.
It's vital that national authorities are not able to query or enumerate what
credentials may exist and equally important that end users remain in control
of what information is provided.


### Avoiding Dependence

Any credential system needs to carefully consider
what might happen if someone is unable to authenticate or they refuse to.

A protection that might protect people who cannot provide a credential,
for [any reason](#exclusion),
might be to artificially induce a non-trivial failure rate
even where credentials are available and valid.
This might ensure that sites do not come to assume
that all users are equally able to produce a credential
and so build systems to handle failures.

Any choice to induce such failures needs to be balanced
against the potential for fallback mechanisms
to be considerably less private.


## Call to Action

The TAG supports the work on digital credentials.
And we also encourage the groups working in this space to consider all the
risks associated with these technologies with open eyes, and to develop mitigations
where possible. We encourage threat modelling to understand how these technologies
can be misused and potentially lead to unintended and negative societal consequences.

In the [[[ETHICAL-WEB-PRINCIPLES]]], we called for
putting "internationally recognized human rights at the core of the web platform".
We can think of no area of current work where this is more important.

  </body>
</html>
